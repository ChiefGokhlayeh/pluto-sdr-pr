\chapter{Passivradar Aufbau}\label{sct:setup}
Das Passivradar setzt sich zusammen aus Hardwarekomponenten, wie Antennen und Empfänger, sowie Softwarekomponenten, welche die empfangen Signale auswerten. Anschließend wird eine Vorhersage über die Position und Geschwindigkeit des Objekts getroffen. Dieses Kapitel beschäftigt sich mit den Komponenten, die in diesem Projekt eingesetzt werden. Dies beinhaltet Algorithmen zur Synchronisation des Referenzsignals mit dem reflektierten Signal, sowie weitere Algorithmen zur Bestimmung der Position und Geschwindigkeit.
\section{Hardware}
Die Hardware eines Passivradars setzt sich zusammen aus Empfängern und Antennen. Verwendet werden in diesem Projekt zwei Pluto SDRs. Angeschlossen werden diese an jeweils eine Yagi Antenne um Referenz- und Echosignal getrennt zu empfangen. Außerdem teil des Hardware-Aufbaus ist ein externer Oszillator zur Synchronisation der beiden Empfänger. Hierzu wird einen OCXO (Oven Controlled Crystal Oscillator) verwendet.
\subsection{ADALM-Pluto SDR}\label{sct:sdr}
Bei dem hier verwendeten SDR handelt es sich um ein ADALM
PLUTO SDR\@. Hauptgrund, warum sich für dieses Gerät entschieden wurde, ist der günstige Preis und die verhältnismäßig hohe Bandbreite dieses Geräts, welche bei bis zu \SI{20}{\mega\hertz} liegt. Die Bandbreite des Beleuchtersignals, das hier für Passivradar verwendet wird beträgt \SI{5}{\mega\hertz}, was einige SDR nicht aufbringen können. Außerdem besitzt das SDR eine frei wählbare Tuner-Frequenz von \SI{325}{\kilo\hertz} bis zu \SI{3.8}{\giga\hertz}. Weitere Daten können Tabelle~\ref{table:sdr} entnommen werden.

\begin{table}
    \centering
        \begin{tabular}[h]{rl}
            Empfänger & 325 KHz - 3.8MHz Frequenz Abdeckung, 200kHz - 20 MHz Bandbreite\\
            Sender  & 325 KHz - 3.8MHz Frequenz Abdeckung, 200kHz - 20 MHz Bandbreite\\
            Anschlüsse & USB 2.0 OTG, USB power adapter\\
            Kompatibilität & MATLAB, Simulink, GNU Radio, Python, und weitere\\
        \end{tabular}
    \caption{Daten des ADALM PlutoSDR}\label{table:sdr}
\end{table}

\subsubsection{Synchronität}\label{sct:Oscillator}
Zur Aufnahme des Referenzsignals als auch des reflektierten Signals werden jeweils ein Pluto-SDR benötigt, diese zwei müssen nun synchron betrieben werden, um das Referenzsignal zu dem reflektierten Signal zu ordnen zu können. Dies wird erreicht durch Daisy Chaining  der beiden Uhren der SDRs und einem OCXO Oscillator als externen Uhr. Die Abbildungen ~\ref{fig:Pluto} zeigen dann den fertigen Aufbau der Beiden SDRs und im Schaltplan in Abbildung ~\ref{fig:Clock} ist zur erkennen wie die Uhr der jeweiligen SDRs aufgebaut ist.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/Schaltplan_Clock.png}
    \caption{Schaltplan der Clock des Pluto SDRs} \label{fig:Clock}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[Pluto mit Clock]{0.3\textwidth}
        \includegraphics[width=\textwidth]{images/Pluto_1.jpeg}
        \caption{PlutoSDR, OCXO Oscillator}
    \end{subfigure}
    \begin{subfigure}[Daisy Chaining]{0.3\textwidth}
        \includegraphics[width=\textwidth]{images/Pluto_2.jpeg}
        \caption{Daisy Chaining}
    \end{subfigure}
    \begin{subfigure}[Gesamter Aufbau]{0.3\textwidth}
        \includegraphics[width=\textwidth]{images/Pluto_4.jpeg}
        \caption{Der gesamte Aufbau}
    \end{subfigure}
    \caption{Aufbau der Hardware mit den beiden Plutos und der Clock} \label{fig:Pluto}
\end{figure}

\subsection{Antenne}
In diesem Aufbau werden zwei Antennen die für DVB-T gedacht sind verwendet. Die Antenne ist ein Yagi Antenne mit 43 Elementen wie man im Abbildung ~\ref{fig:antenne} sieht die im Frequenzbereich von 470 bis 862 MHZ arbeitet, was für unseren Anwendungsfall sehr gut geeignet ist. Die weiteren Daten zur Antenne stehen in der Tabelle ~\ref{table:antenne}.

\begin{table}
    \centering
    \begin{tabular}[h]{rl}
        Antenne         & SKT SL43-01 UHF 43            \\
        Antennengewinn  & 11..13 dB                     \\
        Frequenzbereich & 470-862 MHz                   \\
        Halbwertsbreite & horiz. 30...40°/ver. 35...50° \\
    \end{tabular}
    \caption{Daten der SKT SL43-01 UHF 43 Antenne}\label{table:antenne}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/antenne.png}
    \caption{SKT SL43-01 UHF 43 Antenne}\label{fig:antenne}
\end{figure}
\section{Signal}
Das hier verwendete Signal beruht auf der LTE Technik. Long Term Evolution oder kurz LTE und war vor allem dadurch erfolgreich, dass eine neue Übertragungstechnik verwendet wurde, mit der das Multipath-Fading-Effekt umgangen wurde. Der Multipath-Fading-Effekt tritt auf, wenn die Länge eines Übertragungsschrittes verkleinert wird, was bei einer Verzögerung des Signals dazu führen kann, dass sich die einzelnen Übertragungsschritte überlappen. Die Technik, die dem gegen wirkt, hat die Bezeichnung Orthogonal Frequenz Division Multiplexing (OFDM) Technik. Hierbei wird ein schneller Datenstrom in viele kleine langsame unterteilt, da so kein Multipath-Fading-Effekt auftritt, nach dem Übertragen wird Datenstrom wieder zusammengeführt. OFDM wird in einem der unter Kapitel noch genauer erläutert werden.
Die Bandbreite von LTE ist recht variable wählbar und liegt zwischen 1,25 MHz und 20 MHz, in der bei diesem Projekt auf LTE verwendeten Übertragungstechnik liegt, die Bandbreite bei 5 MHz. Die Wahl der Bandbreite hängt hier sehr davon ab, was das Ziel für die Applikation ist, theoretisch können aber bei einer Bandbreite von 20MHz und sehr guten Übertragungsbedingungen Datenraten von über 100Mbit/s erreicht werden. Weitere nennenswerte Änderungen waren die Einführung von Multiple Input Multiple Output (MIMO) Übertragungen sowie der Fokus auf das paketvermittelnde Internet-Protokoll (IP).~\cite[S.205f]{Sauter2018}
\subsection{Aufbau von LTE}
Ein LTE-Signal besteht aus 504 unterschiedlichen Zellidentitäten auf physikalischer Ebene, diese sind in 168 unterschiedliche physikalischer Gruppen unterteilt. Eine Zellidentität setzt sich zusammen aus Identifikationsnummer der Gruppe sowie der Identifikationsnummer der jeweiligen physikalischen Ebene in der physikalischen Gruppe zusammen. Somit berechnet sich die Zellidentität wie folgt: $$N_{ID}^{cell}=3N_{ID}^{(1)}+N_{ID}^{(2)}$$ Hierbei gilt, dass jede Gruppe eine Nummer $N_{ID}^{(1)}$ zur Identifikation im Bereich von 0 bis 167 besitzt. Außerdem liegt die Identifikationsnummer $N_{ID}^{(2)}$ der physikalischen Ebene in der physikalischen Gruppe im Bereich von 0 bis 2.
Zur Synchronisation des Signals benutzt LTE sowohl ein Primary Synchronisation Signal (PSS) als auch ein Secondary Synchronisation Signal (SSS).~\cite[S.~180]{etsi2021136}

\subsubsection{Framestrukturtyp}
Der Framestrukturtyp 1, der für Vollduplex und Halbdublex FDD gilt, hat eine Länge von 10 ms und besteht aus 10 Subframes, die jeweils eine Länge von $1ms$ haben und von 0 bis 9 durchnummeriert sind. Bei Subframes, die die Frequenz $\Delta f=2.5kHz$, $\Delta f=7.5kHz$ oder $\Delta f=15kHz$ besitzen wird ein Subframe in zwei Slots unterteilt, wo die länge jedes Slots $0.5ms$ beträgt. Bei einer Subframefrequenz von $\Delta f=1.25kHz$ besteht der Subframe aus keinen Slots und seine Länge beträgt $1ms$. Wenn die Übertragungsfrequenz bei $\Delta f=0.37kHz$ liegt, besitzt ein Slot eine Länge von $3ms$. Eine Periode ist $40ms$ lang und besteht dem nach aus 12 Slots, die von 0 bis 13 durchnummeriert sind. Die übertragung beginnt somit dann bei jedem vierten Frame. Außerdem stehen für FDD 10 Subframes, 20 Slots oder bis 60 Subslots zur Verfügung.

\subsubsection{Primary Synchronisation Signal (PSS)}
 PSS wird in jeden Frame zweimal übertragen, und zwar im ersten und 10 Slot. Innerhalb jedes Slots wird das PSS im letzten OFDM Symbol übertragen. Was UE damit erreicht mit dem PSS erreicht ist eine Subframe Synchronisation, eine Slot Synchronisation sowie eine Symbol Synchronisation. Außerdem kann die Mitte des jeweiligen Kanals bestimmt werden in der Frequenz Domain. Ebenfalls wird die passenden PCI aus den drei verschiedenen PCI erkannt.
 Die Sequenz des PSS wird generiert durch die Zadoff-Chu erzeugt. Zadoff-Chu: $$ 	\operatorname{d_u}(n)=\begin{cases} e^{-j\frac{\pi un(n+1)}{63}}, & n=0,1,...,30 \\ e^{-j\frac{\pi u(n+1)(n+2)}{63}}, & n=31,32,...,61 \end{cases}$$~\cite[S.~181]{etsi2021136}. Bei einer MBMS-Zelle, die die Rahmenstruktur 1 verwendet, wird das Synchronsignal im Slot 0 in jedem vierten Subframe übertragen.
\subsubsection{Secondary Synchronisation Signal (SSS)}
Die für den sekundären Synchronisationssignal verwendete Sequenzen d(0),…,d(61) von zwei verknüpften Binärsequenzen der Länge 31. Die verknüpften Sequenzen werden mit einer Verschlüsselungssequenz aus dem ersten Synchronisationssignal verwurschtelt. Die Zuordnung der Sequenz zu den Resource-Elementen hängt von der Framestruktur ab. Bei einem Subframe des Framestrukturtyp 1 wird für das sekundäre Synchronisationssignal derselbe Antennenanschluss wie für das erstes verwendet. ~\cite[S.~183]{etsi2021136}

\subsection{OFDM}
Wie schon thematisiert wird bei LTE die OFDM Technik verwendet, in diesem Unterkapitell wird nun auf die Technik genauer eingegangen. Nochmal zu Wiederholung durch das Orthogonales Frequenzmultiplexverfahren OFDM Technik ist es möglich mehr Daten gleichzeitig zu übertragen dafür wird das Signal aufgeteilt und auf unterschiedlichen Frequenzbändern(engl.: \textit{subcarriers}) übertragen.

Die Signalübertragung eines OFDM besteht aus drei Phasen: Preamble, Header und den Daten. Durch die Preamble wird Zeit Synchronisation, die Offset sowie die Kanalschätzung durchgeführt. Das Preamble besteht aus einer langen und kurzen Sequenz, die kurze ist zur Bestimmung der Zeit die lange ist für die restlichen Bestimmungen. Die kurze Sequenz besteht aus 10 periodischen Segmenten wo jedes die gleiche Abtastung von 16 Abtastungen besitzt. Die lange Sequenz besteht dagegen aus zwei OFDM-Symbolen. Hier folgen auf Schutzintervalle zwei FTT Intervalle.

Der Header eines OFDM besteht aus 5 Feldern der Datenrate (4 Bits), einem Reservierten Bit (1 Bit), der Länge (12 Bits), einem Parität Bit (1 Bit) und dem Schwanz (6 Bits). Beim Datenrate Feld kann hier zwischen 16 Kombinationen gewählt werden. Das Längenfeld gibt Information über die tatsächliche Länge in Bytes der Daten.

Das Datenformat besteht aus vier Felder Service, Nachricht, dem Schwanz und Pad. Die Aufgabe des Padfeldes ist es, die Länge der Daten so anzupassen, dass die Datenlänge ist ein ganzzahliges Vielfaches von N dbps. Die gesamten Daten Länge ergibt sich ausfolgender Gleichung: $$N_{data}=N_{dbps}(Ceiling(\frac{16+8N_{Nachricht}}{N_{dbps}}))$$
wobei $N_{Nachricht}$ die Länge der Nachricht entspricht, die auch im Header übergeben wird. 16 entspricht der Anzahl an Service Bytes und 6 entspricht der Anzahl an Schwanz Bits. Die Anzahl an Pad hängt von der Daten Länge ab und berechnet sich wie folgt: $$N_{pad}=N_{data}-(16-8N_{Nachricht}+6)$$ ~\cite[S.49ff]{Liu2019}

\section{Software}\label{sct:software}

Nachfolgend soll nun die verwendete Softwaresuite erläutert werden. Dazu wird zunächst die zur Aufnahme genutzte Lösung beschrieben. Anschließend wird näher auf die eigens entwickelte Signalverarbeitungskette eingegangen.

\subsection{Aufnahme}

Um Daten vom PlutoSDR zu empfangen bedarf es einer Bediensoftware um den Empfangsprozess zu steuern. Zahlreiche solcher SDR-Anwendungen existieren auf dem Markt, viele davon Open-Source oder als Freeware erhältlich. Der Hersteller selbst, Analog Devices, bietet ein low-level Treiberpaket namens \emph{libiio} (der Name setzt sich zusammen aus dem Unix typischen lib-Präfix für \emph{library} und dem Akronym iio --- %
% cspell:disable-next-line
\textbf{i}ndustrial \textbf{i}nput/\textbf{o}utput%
) an. Mit diesem ist es möglich lokal-, über USB- oder Netzwerk verbundene ADCs und FPGAs von Analog Devices zu steuern. Das Treiberpaket beinhaltet dabei einige Kommandozeilenanwendungen mit denen angeschlossene Geräte enumeriert, einzelne Register gelesen und beschrieben und die Firmware ak­tu­a­li­sie­rt werden können. Darüber hinaus kann über eine API, die Teil der namensgebenden libiio Bibliotheksdatei ist, auf Geräte zugegriffen werden.

Es ist diese API an der die meisten SDR-Anwendungen ansetzten. Welche Funktionen der Hardware dann genau nutzbar sind, hängt von der jeweiligen Anwendung ab. Für die Durchführung dieses Projekts würde sich für die Anwendung SDRangel\footnote{Homepage: \url{https://bit.ly/sdrangel}} von Edouard Griffiths entschieden. Abbildung~\ref{fig:sdrangel_screenshot} zeigt die graphische Oberfläche der Anwendung. Die Software unterstützt das Darstellen und Aufzeichnen von IQ-Rohdaten in einem eigenen Dateiformat. Die Möglichkeit der Live-Darstellung der Daten in Frequenz- und Wasserfalldiagramm hat sich in den Messkampagnen als äußerst hilfreich erwiesen.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{images/sdrangel.png}
    \caption{SDRangel im Replay-Modus einer zuvor angefertigten Messung.}\label{fig:sdrangel_screenshot}
\end{figure}

Da es sich hierbei um Open-Source-Software handelt, konnten benötigte Funktionen oder Bugfixes\footnote{Liste aller Änderungen: \url{https://bit.ly/sdrangel-pr}} direkt selbst implementiert werden, und sind anschließend ins Projekt zurück geflossen. So wurde unter anderem ein Bugfix zur parallelen Nutzung zweier PlutoSDR erstellt, eingereicht und in den Hauptentwicklungszweig des Ursprungsprojekts aufgenommen.

\subsection{Signalverarbeitung}

Die Signalverarbeitungskette stellt den essenziellen Teil dieser Projektarbeit dar. Bereits zu beginn des Projekts wurde sich dafür entschieden, diese weitestgehend in Python zu implementieren. Als Grundlage für mathematische Operationen dient dabei die numerische Mathematikbibliothek \emph{NumPy}. Zusätzlich wird vereinzelt auf Funktionen der \emph{SciPy-Signal} (Grundbausteine für Funktionen der Signalverarbeitung) oder \emph{CuPy} (GPU-beschleunigte Implementierung der NumPy-Funktionen) Bibliotheken zurückgegriffen. Ziel ist es, sich eng vertraut mit den Aspekten der Signalverarbeitung zu machen, und weniger auf vorbereitete Funktionen zurückzugreifen, ohne deren Details zu verstehen. Der umgesetzte Entwicklungsprozess lässt sich dabei grob in zwei Schritte unterteilen. Zunächst werden Algorithmen prototypisch in Form von Jupyter Notebooks implementiert und getestet. Hier konnten die Methoden und Algorithmen interaktiv entworfen werden, bevor sie im zweiten Schritt in solide und testbare Python Module ausgegliedert werden.

Die so entstandene Signalverarbeitungskette ist in Abbildung~\ref{fig:signal_processing_chain} gezeigt. Die Direkt- und Echosignale werden über zwei getrennte Kanäle aufgezeichnet. Die beiden Empfänger sind dabei am Wandler phasen- und frequenzkohärent getaktet. Durch die Wandler entsteht ein analytisches Zeitsignal, bestehend aus einer in- und einer \(90^\circ \) verschobenen Phasenkomponente %
% cspell:disable-next-line
(engl.\@ \textbf{I}n-phase und \textbf{Q}uadrature-phase). %
Nach der Wandlung werden diese Daten per USB-Schnittstelle an einen Computer übertragen und dort aufgezeichnet. Dabei ist anzumerken, dass bereits durch die USB-Übertragung jegliche Synchronität der beiden Kanäle verloren geht. Um dem entgegen zu wirken, wird im Dateikopf jeder Aufzeichnung ein Millisekunden genauer Zeitstempel hinterlegt. Da jedoch weder das Betriebssystem noch die Aufnahmesoftware harte Echtzeit unterstützt ist auch hier von mehreren Millisekunden Jitter auszugehen. Um dies zu kompensieren wird eine Synchronisierungsschnittstelle eingesetzt, die versucht, die beiden Datenströme zeitlich anzugleichen. Dazu wird zunächst eine grobe Angleichung mittels Zeitstempel aus der Aufzeichnung vorgenommen, anschließend wird versucht über die im LTE Signal enthaltenen Synchronisierungssequenzen eine OFDM-Symbol genaue Synchronisierung herzustellen. So entstehen zwei in Zeit, Frequenz und Phase synchronisierte Datenströme, die für die weitere Prozessierung verwendet werden.

Die Mitführung des Referenzkanals ermöglicht grobe Clutter Suppression mittels \emph{CLEAN} Algorithmus~\cite{Kulpa2019}. Dazu soll im Folgenden genauer auf die Kernelemente \emph{CAF} und \emph{CLEAN} eingegangen werden. Finales Ergebnis der Prozesskette ist eine von Clutter bereinigte Range-Doppler Matrix. Zukünftige Arbeiten könnten an dieser Stelle ansetzen und die Informationen aus der Range-Doppler Matrix zur Alarmerzeugung nutzen.

\begin{figure}[htb]
    \centering
    \begin{tikzpicture}[
            flow node/.style={
                    draw,
                    fill=blue!20,
                    rounded corners,
                    minimum height=2em,
                    minimum width=5cm,
                },
            every edge quotes/.style={
                    fill=white,
                    rounded corners,
                    fill opacity=0.8,
                    text opacity=1,
                    font=\scriptsize,
                }
        ]
        \coordinate (origin) at (0,0);

        \node (pluto_a) [flow node, left=0.5cm of origin, anchor=east] {PlutoSDR A};
        \node (pluto_b) [flow node, right=0.5cm of origin, anchor=west] {PlutoSDR B};

        \node (antenna_a) [bareRXantenna, above=1.5cm of pluto_a]{Rx A};
        \node (antenna_b) [bareRXantenna, above=1.5cm of pluto_b]{Rx B};

        \node (recording_ref) [flow node, below=1.5cm of pluto_a, anchor=north] {Aufzeichnung (Ref.)};
        \node (recording_surv) [flow node, below=1.5cm of pluto_b, anchor=north] {Aufzeichnung (Surv.)};

        \node (parser_ref) [flow node, below=1.5cm of recording_ref, anchor=north] {Parser};
        \node (parser_surv) [flow node, below=1.5cm of recording_surv, anchor=north] {Parser};

        \path let \p1=($(parser_ref.south)!0.5!(parser_surv.south)$) in node (sync) [flow node, below=1.5cm of (\p1), anchor=north] {Synchronisation};

        \node (caf) [flow node, below=1.5cm of sync, anchor=north] {CAF};

        \node (clean) [flow node, right=1.5cm of caf, anchor=west] {CLEAN};

        \node (display) [flow node, below=1.5cm of caf, anchor=north] {Anzeige};

        \draw (antenna_a) -- (pluto_a);
        \draw (antenna_b) -- (pluto_b);
        \path (pluto_a) edge [->,"IQ Rohdaten"] (recording_ref);
        \path (recording_ref) edge [->,"\directory{reference.sdriq} Datei"] (parser_ref);
        \path (parser_ref) edge [->,"Zeitsignal"] (sync);
        \path (pluto_b) edge [->,"IQ Rohdaten"] (recording_surv);
        \path (recording_surv) edge [->,"\directory{surveillance.sdriq} Datei"] (parser_surv);
        \path (parser_surv) edge [->,"Zeitsignal"] (sync);
        \path (sync) edge [->,"(2x) Sync. Zeitsignal"] (caf);
        \path let \p1=($(caf.east) + (0,0.2cm)$), \p2=($(clean.west) + (0,0.2cm)$) in (\p1) edge [->,"Range-Doppler Matrix" {right,rotate=40}] (\p2);
        \path let \p1=($(clean.west) - (0,0.2cm)$), \p2=($(caf.east) - (0,0.2cm)$) in (\p1) edge [->,"Bereinigtes Zeitsignal" {right,rotate=-40}] (\p2);
        \path (caf) edge [->,"Range-Doppler Matrix"] (display);
    \end{tikzpicture}
    \caption{Schematische Darstellung der Signalverarbeitungskette.}\label{fig:signal_processing_chain}
\end{figure}

\subsubsection{Ambiguity Funktion}\label{sct:ambiguity_function}

Wie bereits durch die Erläuterung des Messprinzips in Kapitel~\ref{chp:theory_of_operation} beschrieben, basiert die Entfernungsschätzung in Passivradarsystemen auf der zeitlichen Korrelation zwischen Referenz- und Echosignal. Neben dem zeitlichen Versatz, welcher Rückschlüsse auf die Entfernung erlaubt, kann unter Berücksichtigung des Frequenzversatzes beider Signale auch eine bistatische Geschwindigkeit ermittelt werden. Um den Versatz eben dieser beiden Größen bestimmen zu können, wird in der Radartechnik allgemein auf die s.\,g.\@ Kreuzambiguitätsfunktion (CAF) zurückgegriffen. Darunter wird die Korrelation zweier Eingangssignale unter Variation des Zeit- und Frequenzversatzes verstanden. Die resultierende Größe gibt Aufschluss über die \emph{Ähnlichkeit} beider Signale an den gewählten Funktionsparametern. Mathematisch ausgedrückt ist die CAF gegeben durch~\cite[S.~132]{Malanowski2019}:%
%
\begin{equation}\label{equ:cross_ambiguity_function}
    \psi(t, f_{\text{d}}) = \int_{-T/2}^{T/2} {x_{e}(s) \cdot x_{r}^{*}} \left( s - t \right)\mathrm{e}^{\mathrm{j} 2 \pi f_{d} s} \, \text{d} s
\end{equation}%
%
Die Variablen \(t\) und \(f_{d}\) steuern dabei den Zeit- bzw. Frequenzversatz. Die Funktionen \(x_{r}(s)\) und \(x_{e}(s)\) bestimmen das Referenz- bzw. Echosignal im Zeitbereich. \(T\) stellt den Integrationsintervall (auch Coherent Processing Interval [CPI]) dar. \({\{}\cdot{\}}^{*}\) wird hier als Operator der komplexen Konjugation und \(\mathrm{j}\) als imaginäre Einheit genutzt.

Da in der Regel mit digitalen Systemen gearbeitet wird, soll an dieser Stelle auch die zeitdiskrete Variante der CAF eingeführt werden:%
%
\begin{equation}\label{equ:cross_ambiguity_function_digital}
    \psi(m, k) = \sum_{n = 0}^{N - 1}{x_{e}(n) \cdot x_{r}^{*}(n - m) \mathrm{e}^{-\mathrm{j} \frac{2 \pi}{N} k n}}
\end{equation}%
%
Wobei nun \(m\) den Zeitversatz in Samples, \(k\) den Frequenzversatz in Frequency Bins, sowie \(N\) die Anzahl Samples im Integrationsfenster ausdrückt.

In der Praxis wird die CAF für ein ausgewähltes Intervall der Eingangsparameter \(m\) und \(k\) bzw.\@ \(t\) und \(f_d\) berechnet. Daraus resultiert eine Range-Doppler Map, in der nach potenziellen Zielen, s.\,g.\@ Alarmen, gesucht werden kann. Die Einzelheiten solcher Detektionsalgorithmen, wie z.\,B.\@ dem weit verbreitete Constant False Alarm Rate Detector (CFAR)~\cite[S.~208--230]{Malanowski2019}, sind nicht mehr Teil dieser Arbeit. Daher soll zunächst der Fokus auf der CAF bleiben.

Zwar liefert eine direkte Implementierung der Gleichung~\ref{equ:cross_ambiguity_function_digital} mittels gängiger numerischer Basisoperationen bereits das gewünschte Ergebnis, jedoch ist die direkte Berechnung mit erheblicher Zeitkomplexität verbunden. Im Rahmen dieser Projektarbeit wurden daher verschiedene Implementierungen der CAF umgesetzt, auf die im Folgenden kurz eingegangen werden soll. Alle Implementierungen wurden mit einfachen synthetischen Beispielen, sowie gegeneinander getestet.

\begin{description}
    \item[Direkte Implementierung]

          Diese erste Implementierung dient primär als Verifikationswerkzeug der anderen Varianten. Die CAF wird dabei naiv über eine direkte Übersetzung der Gleichung~\ref{equ:cross_ambiguity_function_digital} in numerische Operationen erzielt. Darüber hinaus werden keinerlei Vereinfachungen zur effizienteren Berechnung vorgenommen. Für jedes Eingangspaar \(m\) und \(k\) wird zunächst eine Matrixzeile des entsprechend zeitlich verschobenen Referenzsignals angelegt. Anschließend wird das Schur Produkt des komplex konjugierten und verschobenen Referenzsignals mit dem Echosignal gebildet. Schließlich muss die so entstandene \emph{Matrix aus Verzögerungsprodukten} nun mit der analog aufgebauten komplexen Doppler-Exponenten Matrix multipliziert werden.

          Ein sich aus dieser Herangehensweise ergebender Vorteil ist die Möglichkeit, beliebige Permutationen der Eingangspaare \(m\) und \(k\) zu bestimmen. Entscheidender Nachteil ist die hohe Zeitkomplexität dieses Algorithmus.
    \item[Fine Mode (CPU)]

          Ein approximativer Algorithmus zur Bestimmung der CAF, erstmals beschrieben in~\cite{Stein1981}. Auszeichnende Charakteristik ist die verringerte Zeitkomplexität bei relativ geringem Implementierungsaufwand. Eine alternative Herleitungen basieren auf~\cite{Yatrakis2001} und~\cite[S.~135--136]{Malanowski2019} wurde letztendlich implementiert. Die Kernidee basiert auf der Annahme, dass der Dynamikbereich der Dopplerfrequenz deutlich geringer als die Samplerate \(F_{s} >> f_{d,max}\) ist. Diese Annahme lässt sich auf das in dieser Arbeit betrachtete Szenario folgendermaßen ausweiten: Mit einer angenommenen maximalen Dopplergeschwindigkeit von \SI{100}{\metre\per\sec} (Flugzeug in Landeanflug) lässt sich der Dynamikbereich durch umstellen der Gleichung~\ref{equ:bistatic_velocity} bestimmen. Somit gilt: % chktex 35
          \begin{equation*}
              f_{d,max} = \left| \SI{624}{\mega\hertz} \cdot \frac{\SI{1000}{\metre\per\sec}}{\SI{3e8}{\metre\per\sec}} \right| \approx \SI{208}{\hertz} << F_s = \SI{5}{\mega\hertz} % chktex 35
          \end{equation*}

          In~\cite{Yatrakis2001} wird basierend auf dieser Ungleichung eine Approximation vorgenommen, die es erlaubt, das Problem in drei Schritten zu lösen. Vereinfacht lauten diese:
          \begin{enumerate}
              \item Berechne das komplexe Produkt zwischen Echo und dem dem um \(\tau \) verzögerten Referenzsignal.
              \item Dezimiere das Verzögerungsprodukt um \(L << F_s / 2 \pi v_{max} \). Wobei \(v_{max}\) die maximal erwartete Dopplergeschwindigkeit in \si{\metre\per\second} darstellt. % chktex 35
              \item Berechne die \(\mathbf{DFT} {\{ \cdot \}}\) des dezimierten Produktes.
          \end{enumerate}

          Abbildung~\ref{fig:caf_fine_mode_schematics} zeigt ein Blockschaltbild des beschriebenen Algorithmus. Die Terme \(x_{r}(n)\) und \(x_{e}(n)\) bilden die Samples des Referenz- bzw. Echosignals, wobei das Echosignal zunächst komplex-konjugiert wird. \(z^{a}\) repräsentiert eine Totzeit um \(a\) Samples. Anschließend werden die Signale multipliziert, woraus sich das Verzögerungsprodukt ergibt. Das gemischte Ergebnis wird durch einen Tiefpassfilter mit einer Grenzfrequenz von \(\nicefrac{1}{L}\) geführt. Danach wird eine Dezimierung der Schrittgröße \(L\) angewendet\footnote{NumPy's \lstinline{decimate} führt sowohl Tiefpassfilterung als auch Dezimierung in einer Operation durch.}. Ziel dieser beiden Operationen ist es, den interessanten Frequenzbereich (gegeben durch \(f_{d,max}\)) auf die gesamte Breite des Spektrums aufzuspreizen. Damit werden die Punkte der nachfolgenden \(\mathbf{DFT} {\{ \cdot \}}\) auf den interessenten Frequenzbereich limitiert, statt sie über die gesamte Bandbreite aufzuteilen. Das Ergebnis der \(\mathbf{DFT} {\{ \cdot \}}\) repräsentiert eine Zeitscheibe der Range/Doppler Matrix. % chktex 35

          Zur Überprüfung auf Korrektheit, wurden die Rechenergebnisse mit denen der Direkten Implementierung verglichen. Entscheidender Vorteil dieser Variante ist die deutlich schnellere Berechnung, dank Nutzung des effizienten \(\mathbf{FFT} {\{ \cdot \}}\) Algorithmus.

    \item[Fine Mode (GPU)]

          Eine GPU-optimierte Implementierungen des Fine Mode Algorithmus. Funktionsprinzip und Ablauf sind mit der CPU-Version identisch, jedoch werden sämtliche Operationen auf der GPU ausgeführt.

          In der Praxis hat sich gezeigt, dass diese Variante zwar auf ein einzelnes Integrationsintervall bezogen schneller rechnet, jedoch ist bei der vorliegenden Implementierung die Prozessierung mehrerer Range-Doppler Matrizen im Batch-Modus schnell durch den geringeren VRAM limitiert.
\end{description}

\begin{figure}[htb]
    \centering
    \begin{tikzpicture}[
        result node/.style={
                draw,
                minimum width=1.75cm,
                minimum height=2em,
                thick,
            },
        function node/.style={
                draw,
                minimum width=2.5cm,
                minimum height=2em,
            },
        mixer node/.style={
                mixer,
                scale=0.5,
            },
        delay node/.style={
                function node,
                minimum width=3em,
            },
        input node/.style={
                draw,
                minimum width=1.5cm,
                minimum height=2em,
                thick,
            },
        ghost/.style={
                inner sep=0,
                outer sep=0,
                minimum width=0,
                minimum height=2em,
                anchor=center,
            },
        -|/.style={to path={-| (\tikztotarget)}},
        |-/.style={to path={|- (\tikztotarget)}}
        ]
        \node [result node] (y0) at (0, 0) {\(\psi (0, \cdot)\)};
        \node [result node, anchor=north, below=0.25cm of y0.south] (y1) {\(\psi (1, \cdot)\)};
        \node [result node, anchor=north, below=0.25cm of y1.south] (y2) {\(\psi (2, \cdot)\)};
        \node [result node, anchor=north, below=0.25cm of y2.south] (yD) {\(\psi (\dots, \cdot)\)};
        \node [result node, anchor=north, below=0.25cm of yD.south] (yN) {\(\psi (M, \cdot)\)};

        \node [function node, anchor=east, left=0.25cm of y0.west] (dft0) {\(\mathbf{DFT} {\{ \cdot, L \}}\)};
        \node [function node, anchor=east, left=0.25cm of y1.west] (dft1) {\(\mathbf{DFT} {\{ \cdot, L \}}\)};
        \node [function node, anchor=east, left=0.25cm of y2.west] (dft2) {\(\mathbf{DFT} {\{ \cdot, L \}}\)};
        \node [function node, anchor=east, left=0.25cm of yD.west] (dftD) {\(\mathbf{DFT} {\{ \cdot, L \}}\)};
        \node [function node, anchor=east, left=0.25cm of yN.west] (dftN) {\(\mathbf{DFT} {\{ \cdot, L \}}\)};

        \path (dft0) edge [->] (y0);
        \path (dft1) edge [->] (y1);
        \path (dft2) edge [->] (y2);
        \path (dftD) edge [->] (yD);
        \path (dftN) edge [->] (yN);

        \node [function node, anchor=east, left=0.25cm of dft0.west] (dec0) {\(\mathbf{DEC} {\{ \cdot, L \}}\)};
        \node [function node, anchor=east, left=0.25cm of dft1.west] (dec1) {\(\mathbf{DEC} {\{ \cdot, L \}}\)};
        \node [function node, anchor=east, left=0.25cm of dft2.west] (dec2) {\(\mathbf{DEC} {\{ \cdot, L \}}\)};
        \node [function node, anchor=east, left=0.25cm of dftD.west] (decD) {\(\mathbf{DEC} {\{ \cdot, L \}}\)};
        \node [function node, anchor=east, left=0.25cm of dftN.west] (decN) {\(\mathbf{DEC} {\{ \cdot, L \}}\)};

        \path (dec0) edge [->] (dft0);
        \path (dec1) edge [->] (dft1);
        \path (dec2) edge [->] (dft2);
        \path (decD) edge [->] (dftD);
        \path (decN) edge [->] (dftN);

        \node [function node, anchor=east, left=0.25cm of dec0.west] (lpf0) {\(\mathbf{LPF} {\{ \cdot, \nicefrac{1}{L} \}}\)};
        \node [function node, anchor=east, left=0.25cm of dec1.west] (lpf1) {\(\mathbf{LPF} {\{ \cdot, \nicefrac{1}{L} \}}\)};
        \node [function node, anchor=east, left=0.25cm of dec2.west] (lpf2) {\(\mathbf{LPF} {\{ \cdot, \nicefrac{1}{L} \}}\)};
        \node [function node, anchor=east, left=0.25cm of decD.west] (lpfD) {\(\mathbf{LPF} {\{ \cdot, \nicefrac{1}{L} \}}\)};
        \node [function node, anchor=east, left=0.25cm of decN.west] (lpfN) {\(\mathbf{LPF} {\{ \cdot, \nicefrac{1}{L} \}}\)};

        \path (lpf0) edge [->] (dec0);
        \path (lpf1) edge [->] (dec1);
        \path (lpf2) edge [->] (dec2);
        \path (lpfD) edge [->] (decD);
        \path (lpfN) edge [->] (decN);

        \node [mixer node, anchor=east, left=0.25cm of lpf0.west] (mixer0) {};
        \node [mixer node, anchor=east, left=0.25cm of lpf1.west] (mixer1) {};
        \node [mixer node, anchor=east, left=0.25cm of lpf2.west] (mixer2) {};
        \node [mixer node, anchor=east, left=0.25cm of lpfD.west] (mixerD) {};
        \node [mixer node, anchor=east, left=0.25cm of lpfN.west] (mixerN) {};

        \path (mixer0.east) edge [->] (lpf0);
        \path (mixer1.east) edge [->] (lpf1);
        \path (mixer2.east) edge [->] (lpf2);
        \path (mixerD.east) edge [->] (lpfD);
        \path (mixerN.east) edge [->] (lpfN);

        \node [delay node, anchor=east, left=0.25cm of mixer0.west] (delay0) {\(z^{0}\)};
        \node [delay node, anchor=east, left=0.25cm of mixer1.west] (delay1) {\(z^{-1}\)};
        \node [delay node, anchor=east, left=0.25cm of mixer2.west] (delay2) {\(z^{-2}\)};
        \node [delay node, anchor=east, left=0.25cm of mixerD.west] (delayD) {\(z^{-\dots}\)};
        \node [delay node, anchor=east, left=0.25cm of mixerN.west] (delayN) {\(z^{-M}\)};

        \path (delay0.east) edge [->] (mixer0.west);
        \path (delay1.east) edge [->] (mixer1.west);
        \path (delay2.east) edge [->] (mixer2.west);
        \path (delayD.east) edge [->] (mixerD.west);
        \path (delayN.east) edge [->] (mixerN.west);

        \node [input node, anchor=east, left=0.5cm of delay0.west] (ref) {\(x_{r}(n)\)};
        \node [input node, anchor=south, above=0.25cm of ref.north] (surv) {\(x_{e}^{*}(n)\)};

        \node [ghost, left=0.25cm of delay0.west] (ref_ghost_delay0) {};
        \node [ghost, left=0.25cm of delay1.west] (ref_ghost_delay1) {};
        \node [ghost, left=0.25cm of delay2.west] (ref_ghost_delay2) {};
        \node [ghost, left=0.25cm of delayD.west] (ref_ghost_delayD) {};
        \node [ghost, left=0.25cm of delayN.west] (ref_ghost_delayN) {};

        \path (ref_ghost_delay0.center) edge [->] (delay0.west);
        \path (ref_ghost_delay1.center) edge [->] (delay1.west);
        \path (ref_ghost_delay2.center) edge [->] (delay2.west);
        \path (ref_ghost_delayD.center) edge [->] (delayD.west);
        \path (ref.east) edge [-|] (ref_ghost_delayN.center) (ref_ghost_delayN.center) edge [->] (delayN.west);

        \node [ghost, left=0.125cm of ref_ghost_delay0.center] (surv_ghost0_mixer0) {};
        \node [ghost, left=0.125cm of ref_ghost_delay1.center] (surv_ghost0_mixer1) {};
        \node [ghost, left=0.125cm of ref_ghost_delay2.center] (surv_ghost0_mixer2) {};
        \node [ghost, left=0.125cm of ref_ghost_delayD.center] (surv_ghost0_mixerD) {};
        \node [ghost, left=0.125cm of ref_ghost_delayN.center] (surv_ghost0_mixerN) {};

        \node [ghost, above=0.125cm of surv_ghost0_mixer0.north, minimum height=0] (surv_ghost_mixer0) {};
        \node [ghost, above=0.125cm of surv_ghost0_mixer1.north, minimum height=0] (surv_ghost_mixer1) {};
        \node [ghost, above=0.125cm of surv_ghost0_mixer2.north, minimum height=0] (surv_ghost_mixer2) {};
        \node [ghost, above=0.125cm of surv_ghost0_mixerD.north, minimum height=0] (surv_ghost_mixerD) {};
        \node [ghost, above=0.125cm of surv_ghost0_mixerN.north, minimum height=0] (surv_ghost_mixerN) {};

        \path (surv_ghost_mixer0.center) edge [-|,->] (mixer0.north);
        \path (surv_ghost_mixer1.center) edge [-|,->] (mixer1.north);
        \path (surv_ghost_mixer2.center) edge [-|,->] (mixer2.north);
        \path (surv_ghost_mixerD.center) edge [-|,->] (mixerD.north);
        \path (surv.east) edge [-|] (surv_ghost_mixerN.center) (surv_ghost_mixerN.center) edge [-|,->] (mixerN.north);

        \path (y0.south west) edge [dotted] (y1.north west)
        (y1.south west) edge [dotted] (y2.north west)
        (y2.south west) edge [dotted] (yD.north west)
        (yD.south west) edge [dotted] (yN.north west);
        \path (y0.south east) edge [dotted] (y1.north east)
        (y1.south east) edge [dotted] (y2.north east)
        (y2.south east) edge [dotted] (yD.north east)
        (yD.south east) edge [dotted] (yN.north east);

        \path (y0.north east) -- node [midway,anchor=north,rotate=90] {\tiny Entfernung} (yN.south east);
        \path (yN.south west) -- node [midway,anchor=north] {\tiny Doppler} (yN.south east);
    \end{tikzpicture}

    \caption{Blockdiagramm des Fine Mode CAF Algorithmus.\label{fig:caf_fine_mode_schematics}}
\end{figure}

\subsubsection{CLEAN Algorithmus}

Eine entscheidende Hürde in der Entwicklung eines jeden Radarsystems ist es, gewünschte Signale (Targets) von unerwünschten (Clutter) zu unterscheiden. Selbstverständlich unterscheidet sich welche Reflexionen als Targets oder als Clutter klassifiziert werden je nach Anwendungsfall. Im Falle eines Luftüberwachungsradars werden üblicherweise nur Reflexionen an Flugzeugen als erwünscht angesehen. Neben diesen, empfangen solche Systeme unweigerlich auch Reflexionen an Terrain, Gebäuden, Wolken, Vogelschwärmen, Bodenfahrzeugen oder Schiffen. Diese Clutter-Quellen unterscheiden sich unter anderem in ihrem Radarquerschnitt und somit der Leistung, die sie an einen Empfänger zurückwerfen. Eine besondere Clutter-Quelle speziell bei Passivradar ist das Einleuchten des Direktsignals, bspw.\@ über Nebenkeulen der Empfangsantenne. Dies trifft typischerweise mit deutlich höherer Leistung als die Echos der Targets am Empfänger ein. Es ist daher essenziell, diese und andere Quellen von Clutter zu unterdrücken; man spricht von s.\,g.\@ Clutter-Suppression. Ohne jegliche Form von Unterdrückung werden Zielreflexionen meist komplett vom Clutter verdeckt und sind unmöglich in der Range-Doppler Map auszumachen. Für den Prozess der Clutter-Suppression werden typischerweise adaptive Filter verwendet. Einige verbreitete Ansätze sind in~\cite[S.~177--202]{Malanowski2019} beschrieben.

Aufgrund seines einfachen Aufbaus wird in dieser Projektarbeit der CLEAN Algorithmus zur Clutter-Suppression eingesetzt. Damit wird in der aktuellen Version vornehmlich versucht, die Direkteinstrahlung des Referenzsignals im Überwachungskanal zu unterdrücken. Diese Anwendung wurde unter anderem in~\cite{Feng2013} demonstriert.

Der Funktion des CLEAN Algorithmus liegt folgendes an~\cite{Kulpa2008} angelehnte Empfangsmodell zugrunde. Zunächst wird ein Referenz- und ein Überwachungskanal im Basisband definiert. Der Referenzkanal wird als die gedämpfte und mit additivem weißen Rauschen \(\eta (t)\) beaufschlagte Senderwellenform \(u (t)\) modelliert:
%
\begin{equation}
    y_{ref} (t) = a \cdot u (t) + \eta_{ref} (t)
\end{equation}\label{equ:clean_reference_channel}%
%
Wobei \(a\) die nach Dämpfung verbleibende komplexe Amplitude des Signals darstellt.

Im Überwachungskanal wird diese Wellenform als Summe von \(n\) Reflexion an stationären oder bewegten Objekten behandelt. Die aufgrund der Mehrwegeausbreitung verlängerte Signallaufzeit vom \(i\)-ten Objekt zum Empfänger wird als zum Referenzsignal relativer Zeitversatz \(\tau_{i} \) aufgespielt. Gleichermaßen wird ein Dopplerversatz \(f_{d,i}\) für bewegte Ziele beaufschlagt. Schließlich ist auch der Überwachungskanal einem weißen Rauschen ausgesetzt:%
%
\begin{equation}
    y_{surv} (t) = \sum_{i = 0}^{n}{a_{i} \cdot u (t - \tau_{i}) \cdot \mathrm{e}^{\mathrm{j} 2 f_{d,i} t}} + \eta_{surv} (t)
\end{equation}%
%
Wobei \(\mathrm{j}\) die imaginäre Einheit darstellt. Die so modellierten \(i\) Kopien der vom Sender emittierten Wellenform können sowohl erwünschte Zielreflexionen aber auch Clutter oder Direkteinstrahlung des Referenzsignals sein. Es ist davon auszugehen, dass Direkteinstrahlung und Clutter höhere Amplitude aufweisen, als echte Ziele. Diese werden somit von den unerwünschten Reflexionen \emph{überleuchtet}. Ziel ist es nun, die Parameter \(a_{i}\), \(\tau_{i}\) und \(f_{d,i}\) eben dieser unerwünschten Einstrahlungen zu schätzen, um im nächsten Schritt entsprechend zeit- und frequenzverschobene Senderwellenform vom Überwachungskanal abzuziehen. Übrig bleiben die Reflexionen der erwünschten Ziele.

Die Kernidee des CLEAN Algorithmus besteht nun darin, die genannten Parameter aus den Peaks der Range/Doppler Matrix zu schätzen und rekursiv vom Überwachungskanal abzuziehen. Dabei basiert die Entscheidung, welche Peaks Ziele und welche Clutter darstellen, auf a priori Wissen über das Operationsgebiet. Vorausgesetzt Sender, sowie Empfänger sind stationär; und beide Empfangsantennen in unmittelbarer Nähe zueinander, so ist beispielsweise davon auszugehen, dass der höchste Peak vom Direktsignal bei \(\tau_{direct} \approx 0\) und \(f_{d,direct} \approx 0\) ausgeht. Was fehlt ist die komplexe Amplitude, die aus dem verschobenen Referenzsignal bezogen werden kann. Vor der Subtraktion vom Überwachungskanal, ist sicherzustellen, dass sowohl das geschätzte Clutter-Signal als auch der Überwachungskanal normiert sind.

Das eingeführte Empfangsmodell wird in Abbildung~\ref{fig:clean_signal} demonstriert. Als Senderwellenform dient hier eine gepulste Sinuswelle, dargestellt in~\ref{fig:clean_base_waveform}. Diese geht leicht gedämpft über den Referenzkanal zuzüglich Rauschen am Empfänger ein, und erzeugt das in~\ref{fig:clean_ref_waveform} gezeigte Bild. Der rot markierte Bereich hebt das Direktsignal hervor. Abbildung~\ref{fig:clean_surv_waveform} zeigt den Überwachungskanal. Auch hier leuchtet das Direktsignal ein, allerdings über eine Antennennebenkeule und somit stärker gedämpft als im Referenzkanal. Zusätzlich wird, im Bild blau hinterlegt, das schwache Echo eines Ziels empfangen.

\begin{figure}[htb]
    \centering
    \subcaptionbox{Ausgesendete Wellenform\label{fig:clean_base_waveform}}{
        \includesvg[width=0.9\textwidth]{images/generated/clean_base_waveform.svg}
    }

    \subcaptionbox{Empfangenes Signal im Referenzkanal\label{fig:clean_ref_waveform}}{
        \includesvg[width=0.9\textwidth]{images/generated/clean_ref_waveform.svg}
    }

    \subcaptionbox{Empfangenes Signal im Übertragungskanal\label{fig:clean_surv_waveform}}{
        \includesvg[width=0.9\textwidth]{images/generated/clean_surv_waveform.svg}
    }
    \caption{Empfangsmodell des CLEAN Algorithmus}\label{fig:clean_signal}
\end{figure}

Abbildung~\ref{fig:clean_amb_before_2d} schließlich zeigt die aus Referenz- und Übertragungskanal resultierende CAF\@. Zu erkennen ist die starke Einwirkung des Direktsignals auf die Kreuzambiguitätsfunktion. Das damit verglichen schwache Ziel ist nur noch schwer auszumachen. Die dreidimensionale Darstellung der gleichen CAF in~\ref{fig:clean_amb_before_3d} zeigt dies noch einmal eindrücklich. Abbildung~\ref{fig:clean_amb_after_2d} und~\ref{fig:clean_amb_after_3d} zeigen nun die CAF nach einmaliger Anwendung des CLEAN Algorithmus. Gut erkennbar ist die starke Reduktion des Direktsignals, übrig bleibt das Zielecho und der umgebene Rauschteppich.

\begin{figure}[htb]
    \centering

    \subcaptionbox{2D vor CLEAN\label{fig:clean_amb_before_2d}}{
        \includesvg[width=0.6\textwidth]{images/generated/clean_amb_before_2d.svg}
    }%
    %
    \subcaptionbox{3D vor CLEAN\label{fig:clean_amb_before_3d}}{
        \includesvg[width=0.3\textwidth]{images/generated/clean_amb_before_3d.svg}
    }

    \subcaptionbox{2D nach CLEAN\label{fig:clean_amb_after_2d}}{
        \includesvg[width=0.6\textwidth]{images/generated/clean_amb_after_2d.svg}
    }%
    %
    \subcaptionbox{3D nach CLEAN\label{fig:clean_amb_after_3d}}{
        \includesvg[width=0.3\textwidth]{images/generated/clean_amb_after_3d.svg}
    }
    \caption{Anwendung des CLEAN Algorithmus}\label{fig:clean_application}
\end{figure}

Die bisher besprochene Form des CLEAN Algorithmus geht davon aus, dass die Senderwellenform bekannt ist, und rauschfrei synthetisiert werden kann. In der Praxis geschieht dies bei Digitalsignalen zumeist durch Demodulation und Dekodierung des Referenzkanals~\cite{Feng2013}. Da dieser Ansatz jedoch mit erheblichem Aufwand verbunden ist, setzt diese Projektarbeit auf eine weniger zeitaufwendige Alternative. So wird stattdessen das Referenzsignal als beste verfügbare Approximation der ursprünglichen Senderwellenform genutzt. Damit einhergehend ist von reduzierter Clutter-Suppression Performance auszugehen, da Referenz- und Überwachungskanal möglicherweise unterschiedlicher Rauschcharakteristiken ausgesetzt sind. Zudem kann die Anwendung der Direktpfadunterdrückung auch zur Dämpfung erwünschter Ziele führen, da die in Gleichung~\ref{equ:clean_reference_channel} getroffene Annahme über den Referenzkanal nur bedingt anwendbar ist. Grund hierfür sind die Antennennebenkeulen die bei jeder realen Antenne auftreten. Über diese werden unweigerlich auch Echosignale gewünschter Ziele ins Referenzsignal eingeschleust. Die Subtraktion des Direktsignals vom Überwachungskanal kann dann auch zur Dämpfung eben dieser Ziele führen. Hier liegt Potenzial für weiterführende Arbeiten, die mit besser geeigneten Clutter-Suppression Techniken ansetzen könnten.
